# K16 - Recherche ultra-rapide de vecteurs similaires

K16 est une biblioth√®que Python optimis√©e pour la recherche rapide de vecteurs d'embedding similaires. Elle utilise une structure d'arbre hi√©rarchique avec des optimisations SIMD et Numba pour offrir des performances exceptionnelles.

## Caract√©ristiques

- üöÄ **Performances √©lev√©es** : 50-100x plus rapide que la recherche na√Øve
- üß† **M√©moire optimis√©e** : R√©duction de 50-80% de la consommation m√©moire
- üîç **Pr√©cision √©lev√©e** : Recall > 85% configurable
- üìä **Scalable** : Supporte des millions de vecteurs
- üõ†Ô∏è **Modulaire** : API simple et extensible

## Installation

```bash
# Installation depuis le d√©p√¥t
git clone https://github.com/iapourtous/k16
cd k16
pip install -e .

# Installation avec support GPU (n√©cessite CUDA)
pip install -e ".[gpu]"

# Installation avec outils de d√©veloppement
pip install -e ".[dev]"

# V√©rification de l'installation
python -m k16.cli --version
```

La biblioth√®que peut √©galement √™tre utilis√©e directement en ligne de commande apr√®s installation:

```bash
k16 --version
k16 getData
k16 build
k16 test
k16 api
```

## Guide rapide

K16 propose une interface en ligne de commande simple pour toutes les fonctionnalit√©s:

### 1. T√©l√©charger et pr√©parer les donn√©es

```bash
# T√©l√©chargement de Natural Questions (open)
python -m k16.cli getData

# Options personnalis√©es
python -m k16.cli getData --model intfloat/multilingual-e5-large --batch-size 128
```

### 2. Construire un arbre

```bash
# Construction d'un arbre avec les param√®tres par d√©faut
python -m k16.cli build

# Options personnalis√©es
python -m k16.cli build --max_depth 32 --max_data 256 --k 16 --hnsw
```

### 3. Tester les performances

```bash
# Test avec les param√®tres par d√©faut
python -m k16.cli test

# Options personnalis√©es
python -m k16.cli test --k 100 --queries 1000 --search_type beam --beam_width 3
```

### 4. API REST avec FastAPI

```bash
# D√©marrer l'API REST
python -m k16.cli api

# Options personnalis√©es
python -m k16.cli api --host 0.0.0.0 --port 5000 --reload
```

Endpoints disponibles:
- `GET /`: Informations sur l'API
- `GET /health`: V√©rification de l'√©tat de l'API
- `GET /stats`: Statistiques sur l'arbre et les vecteurs
- `POST /search`: Recherche de vecteurs similaires

Exemple d'utilisation de l'endpoint `/search`:

```bash
curl -X 'POST' \
  'http://localhost:8000/search' \
  -H 'Content-Type: application/json' \
  -d '{
  "query": "comment fonctionne un arbre de recherche?",
  "k": 5
}'
```

R√©ponse:
```json
{
  "results": [
    {
      "question": "Comment fonctionne un arbre binaire de recherche ?",
      "answer": "Un arbre binaire de recherche est une structure de donn√©es...",
      "similarity": 0.89,
      "index": 120
    },
    ...
  ],
  "timings": {
    "encode_ms": 15.5,
    "tree_search_ms": 5.2,
    "filter_ms": 3.1,
    "total_ms": 23.8
  },
  "stats": {
    "candidates_count": 256
  }
}

## Configuration

Toutes les options peuvent √™tre configur√©es dans le fichier `config.yaml`. Voici une documentation d√©taill√©e des param√®tres:

### Configuration g√©n√©rale

```yaml
general:
  debug: false  # Mode debug pour informations suppl√©mentaires
```

### Param√®tres de construction d'arbre

```yaml
build_tree:
  # Param√®tres principaux
  max_depth: 32            # Profondeur maximale de l'arbre
  max_leaf_size: 16        # Taille maximale d'une feuille pour l'arr√™t de la subdivision
  max_data: 256            # Nombre de vecteurs √† stocker dans chaque feuille
  max_workers: 12          # Nombre de processus parall√®les (default: CPU count)
  use_gpu: true            # Utilisation du GPU pour le clustering K-means si disponible
  k: 16                    # Nombre de branches par n≈ìud (non pr√©sent dans l'exemple)

  # Param√®tres d'am√©lioration HNSW
  use_hnsw_improvement: true   # Am√©lioration des candidats avec HNSW apr√®s construction
  prune_unused_leaves: true    # Suppression des feuilles jamais utilis√©es pendant la recherche
  hnsw_batch_size: 1000        # Taille du lot pour les recherches HNSW
  grouping_batch_size: 5000    # Taille du lot pour le regroupement de vecteurs
  hnsw_m: 16                   # Param√®tre M pour HNSW (connections par n≈ìud)
  hnsw_ef_construction: 200    # Param√®tre efConstruction pour HNSW (qualit√© vs vitesse)
```

### Param√®tres de recherche

```yaml
search:
  k: 10                 # Nombre de voisins les plus proches √† r√©cup√©rer
  queries: 100          # Nombre de requ√™tes al√©atoires pour les tests de benchmark
  mode: "ram"           # Mode de chargement: "ram" (complet) ou "mmap" (mapp√© en m√©moire)
  cache_size_mb: 500    # Taille du cache en m√©gaoctets (pour le mode mmap)
  use_faiss: true       # Utilisation de FAISS pour la recherche na√Øve et le filtrage final

  # Configuration de l'algorithme de recherche
  search_type: "single" # Algorithme de recherche: "single" (descente simple) ou "beam" (faisceau)
  beam_width: 1         # Nombre de branches √† explorer simultan√©ment (uniquement pour beam search)
                        # Des valeurs plus √©lev√©es am√©liorent le recall au d√©triment de la vitesse
```

### Param√®tres de repr√©sentation d'arbre

```yaml
use_flat_tree: true     # Utilisation de la structure plate optimis√©e pour une recherche plus rapide

flat_tree:
  # Param√®tres de r√©duction dimensionnelle
  max_dims: 512                     # Nombre de dimensions √† conserver √† chaque niveau
  reduction_method: "directional"   # M√©thode de s√©lection des dimensions: "variance" ou "directional"
```

### Param√®tres de pr√©paration des donn√©es

```yaml
prepare_data:
  model: "intfloat/multilingual-e5-large"  # Mod√®le d'embedding √† utiliser
  batch_size: 128                          # Taille du lot pour l'encodage
  normalize: true                          # Normaliser les embeddings √† la longueur unitaire
```

### Chemins de fichiers et valeurs par d√©faut

```yaml
files:
  vectors_dir: "/path/to/data"  # R√©pertoire des vecteurs
  trees_dir: "/path/to/models"  # R√©pertoire des arbres
  default_qa: "qa.txt"          # Fichier texte par d√©faut
  default_vectors: "data.bin"   # Fichier de vecteurs par d√©faut
  default_tree: "tree.bsp"      # Fichier d'arbre par d√©faut
```

### Configuration de l'API

```yaml
api:
  host: "127.0.0.1"    # Adresse d'h√¥te pour l'API
  port: 8000           # Port pour l'API
  reload: false        # Rechargement automatique pour le d√©veloppement
```

### Impact des param√®tres sur les performances

- **max_depth**: Une profondeur plus √©lev√©e permet une meilleure pr√©cision mais augmente le temps de construction.
- **max_data**: Une valeur plus √©lev√©e am√©liore le recall mais ralentit la recherche.
- **k**: Le nombre de clusters par n≈ìud. Une valeur plus √©lev√©e permet une meilleure pr√©cision mais ralentit la construction.
- **search_type** et **beam_width**: "beam" avec une largeur plus grande am√©liore le recall mais ralentit la recherche.
- **use_hnsw_improvement**: Am√©liore consid√©rablement le recall avec un l√©ger impact sur le temps de construction.

## Structure du projet

- `/k16/` : Package principal
  - `/core/` : Structures de donn√©es principales (Tree, TreeFlat)
  - `/builder/` : Construction d'arbres optimis√©s
  - `/search/` : Algorithmes de recherche
  - `/io/` : Lecture/√©criture de vecteurs et d'arbres
  - `/utils/` : Utilitaires et configuration
- `/tests/` : Tests unitaires et d'int√©gration
- `/data/` : Donn√©es d'exemple
- `/models/` : Arbres pr√©-construits

## Licence

Ce projet est sous licence [MIT](LICENSE).